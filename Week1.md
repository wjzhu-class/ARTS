# Week 1: 
哈哈哈 拖了比较久了，万事开头难嘛。第一周打卡开始。
大概思路是这样的：
A，leetcode题目，准备从最低难度开始刷，反正会持续做，算法经典的那本书还没时间啃，只能慢慢来。反正现在工作中对于算法的要求不高，慢慢磨了。
R，review 全凭个人喜好吧，大牛博客，技术团队博客等等。随便找，觉得有意思的就翻译，写摘要+少量个人见解。
T，Tip每周学习中都会有好多好多，看来是自己知识太贫乏了，所以会不限数量分享一些。
S，Share会分享一些自己的经验，或者是平时遇到的问题和解决思路和思考吧。
就这样，let’s go！

* * *

## Algorithm
>给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。
>你可以假设每种输入只会对应一个答案。但是，你不能重复利用这个数组中同样的元素。

>示例:
>	给定 nums = [2, 7, 11, 15], target = 9
>	因为 nums[0] + nums[1] = 2 + 7 = 9
>	所以返回 [0, 1]

* * *

[https://leetcode-cn.com/problems/two-sum/](https://leetcode-cn.com/problems/two-sum/ "LeetCode-两数之和")
```

	class Solution {
	public int[] twoSum(int[] nums, int target) {
	for(int i=0;i<nums.length;i++)
	{
	for(int j=i+1;j<nums.length;j++)
	{
	if((nums[i]+nums[j])==target)
	{
	return new int[]{i,j};
	}
	else
	{
	continue;
	}
	}
	}
	return null;
	}
	}
```
>就用最普通的方式，完成了一个普通普通的算法，没有做到最优时间，但是但是但是看了题解真的是茅塞顿开！！

* * *

方法一：暴力法
	
```
public int[] twoSum(int[] nums, int target) {
	for (int i = 0; i < nums.length; i++) {
	for (int j = i + 1; j < nums.length; j++) {
	if (nums[j] == target - nums[i]) {
	return new int[] { i, j };
	}
	}
	}
	throw new IllegalArgumentException("No two sum solution");
	}
```

方法二：两遍哈希表
	
```
public int[] twoSum(int[] nums, int target) {
	Map<Integer, Integer> map = new HashMap<>();
	for (int i = 0; i < nums.length; i++) {
	map.put(nums[i], i);
	}
	for (int i = 0; i < nums.length; i++) {
	int complement = target - nums[i];
	if (map.containsKey(complement) && map.get(complement) != i) {
	return new int[] { i, map.get(complement) };
	}
	}
	throw new IllegalArgumentException("No two sum solution");
	}
```

方法三：一遍哈希表
	
```
public int[] twoSum(int[] nums, int target) {
	Map<Integer, Integer> map = new HashMap<>();
	for (int i = 0; i < nums.length; i++) {
	int complement = target - nums[i];
	if (map.containsKey(complement)) {
	return new int[] { map.get(complement), i };
	}
	map.put(nums[i], i);
	}
	throw new IllegalArgumentException("No two sum solution");
	}
```
>仔细琢磨一下，说不上来的感觉，特兴奋，打开新世界的感觉，哈哈哈。

* * *

## Review
[Building a Cross-platform In-app Messaging Orchestration Service](https://medium.com/netflix-techblog/building-a-cross-platform-in-app-messaging-orchestration-service-86ba614f92d8 "Building a Cross-platform In-app Messaging Orchestration Service")
本文首先介绍了netflix app中的消息类型：通知和警告。这一博文主要谈警告渠道的事情。警告是一些重要的可能和用户相关的事件，需要立刻引起用户的注意，可能会在首页弹出来。Netflix经过架构重构以后，将警告的消息的展示定义为四个主要的维度。分别是：时间、频率、用户群。最初可能计划是进行无缝切换，将业务逻辑从UI层迁移到专门的数据服务上去。同时也要考虑跨平台消息和减少AB测试的时间。一个简化的消息服务是从消息生产系统产生消息到消息推送平台，通过不同的消息推送服务推送给不同终端的用户。
因为Netflix的平台设备差异性很大，都有不同的UI，所以他们采用一种定制化的JSON格式协议来实现。
分别是模板ID：用来确定使用的UI模板类型。
模板：用来展示特定模板类型的消息格式。
稿件（Copy):用来交付本地化以后的字符串，并且制定相关的样式。
动作：用来标明执行的动作，其中也包含了稿件。动作中包括了相关的动作类型分类、具体的动作名称、包括在多个动作时，哪个默认强调。同时，每个动作也有一个反馈域，用来收集一些相关信息并返回服务器，包括设备id，平台版本等。返回的数据可以帮助netflix改善和用户交互的相关策略，比如如果一个用户在任意一台设备上点击了忽略，那么一天内所有的设备都不会再提示同样的信息了。
属性：属性帮助UI层来渲染用户界面的信息，如一些黑名单列表，不允许UI层再这些页面打开的时候推送警告信息。同时属性也有一个返回，当消息渲染以后就可以发送。
最后，这个方案的一些挑战之处在于：消息工程师对于UI的理解并不深入，或者并不知道。包括一些具体的技术参数和性能指标。同时，在引入自动化测试以后，也明显提高了测试的效率。最后，本地化质量控制也是一个问题，以前并没有设备来管理获取不同设备实际的本地化展示效果。而现在netflix已经有了这样的测试平台和技术。帮助本地化团队做好相关的工作。

这个方案的一些收益在于：现在可以在所有的设备上有相同的信息警告体验。目前降低了相关的开发实验的时间，因为相关的资源和内容都在消息开发组内部。现在可以执行独立渠道的消息了，而不需要和消息推送发邮件等渠道相互影响。最后我们用性质的监控指标，并集成到了消息推送平台上去。
展望未来，netflix规模越来越大，正因为如此，相关的用户体验也在不停的升级中。一个他们希望能降低研发时间的环节是如何在UI平台上进行相关的用户交互操作。
现在是通过API平台调用后台服务来实现的，这一选择是因为大多数平台都已经同后台业务系统进行了整合了。netflix希望将来能够不再依靠后台服务的支持，而是在前端自主决定将什么信息传递给后台的消息服务中去。

>好了，概述翻译结束，说几点自己的想法：
>1. 给自己挖坑了，其实应该选一篇简单点的不是吗？哈哈哈
>2. 我自认英语水平还是可以的，至少看美剧、去国外交流无压力。但是看技术文档，翻译出来真的是郁闷，当你阅读的时候，你可以理解对方要表达的意思，但是当你自己需要翻译的时候，突然会发现在自己贫乏的语料库中没有一个词能对应的上。果然是输出会帮助自己更好地理解。
>3. netflix案例大家应该看了不少了，给我的感觉就是这个业务量太大了，大到考虑问题都和我们的起点不同。试想我们一般的项目开发，哪有这么大的用户体量的挑战，移动端iOS+Android了不起了是吧，人家做的是全平台的提醒的用户体验设计等等等等。一件事，哪怕再小，只要上了规模，就有优化提升的价值和动力。
>4. 任何时候其实用户反馈的收集很重要，比如app经常会有的，提示信息让用户选择。其实类似的日志和用户互操作的内容都应该记录下来不是么，可以做分析，可以更好地理解用户，或者更好地服务当前这个用户的习惯。当业务体量到达一定量级以后，这些平时觉得无所谓的事情都会变得非常重要，包括做AB test在内。越是大的业务，越要注意细节的提升。持续优化。与CI、CD结合，持续反馈、持续研发。形成闭环。


* * *

## Tip

* Tip1: 尽量用新的技术去解决问题，比如用Lambda+Stream API去解决业务场景上的需求实现。这样做的好处除了目前来说的看上去牛逼、简洁之外。更重要的一点是，在未来Java升级或者更新时候，业务性能会随着相关API的优化而提升，如果是自己的逻辑代码，要想优化其实千难万难不是么？
* Tip2:Stream API也有并行运算的，在合适的场景下有非常好的效果。值得尝试一下。
* Tip3:SimpleDataFormat是线程不安全的，因为业务体量小，我们的系统从来没有因为这个地方出过问题。下一个项目里面，我已经换了joda-time和joda-money了。
* Tip4:Mysql 非唯一索引比唯一索引性能更好。
* Tip5:Mysql count（星）性能最好，做过优化。count是不准确的，需要自己实现。不知道sql server有没有这个问题。
* Tip6:开源有坑、有坑、有坑。重要的事情说3遍。最近一直在调试一个开源软件的集成，当然也和老外沟通过，但是，依然进展缓慢，主要是文档不够全面，传参无样例。而且，不同的API的POST中传参格式居然有一些差别。
* Tip7:同事会挖坑、挖坑、挖坑。更重要的事情说3遍。一台ubuntu服务器，开外网服务这么都测试失败，本地调试ok。排查问题发现是一个HTTP PUT请求没执行成功，服务器上没接收到，是不是一个网络或者防火墙相关配置的问题？找了半天无果，网管说：内网无限制。ok，那我们查服务器，查应用，查源代码。依然无果。系统管理员提了一个建议，换个IP试试看，一换IP TM居然成了。好，那这个IP妖怪，我换个IP映射外网好吧！新IP映射外网，又失败了！好，再找网管，然后，网管说：“哦，可能是有限制？” 最后，原来是外网应用接了WAF，而WAF设备是不分内外网的，so。。。前后几个月时间打水飘。我呵呵呵。。。。。。
* Tip8: 介绍给大家“Coffee Nap”:简单一句话，咖啡20分钟起效，你可以利用这20分钟睡一个午觉，醒来保证精神百倍，因为睡眠周期说超过20分钟就要深睡眠了，强行打断反而会更累。
* 好了，先分享这些乱七八糟的，后面几周再分享别的。
* 

## Share
>第一周的Share不知道说啥好，就说一次自己给自己挖坑的故事吧。


大家都知道，在分布式无状态系统中，我们一般都采用令牌方式而非session方式进行鉴权和管理。 

我手上的一个API平台也是如此，通过JWT格式定制了一个User Token，Token中包含了一些基本信息和用户唯一ID。 

在具体使用中，为了提高性能和吞吐量，通过concurrentHashMap实现并发写入调用日志，并通过线程定期（每分钟）处理日志批量插入数据库。 

然而，在最初设计数据库的时候，没有考虑进行日志的处理和加工，直接将Token主体插入日志表存储。 

当出现用户问题时，我需要先知道用户的唯一ID，通过唯一ID在token表中查到这个用户所有的Token ID，无论是否失效和在用。因为所有的Token ID才是和请求 日志中具体操纵进行一一对应关系的。 

这个方式一直尚可，直到系统上线的几个月后，通过SQL Server Profiler 分析性能，发现一些可以优化的地方，然后顺手写了一个脚本，从Token表中定期删除过期的Token信息，保证数据库的性能。一开始我并没有意识到有什么问题，直到想再次查询用户的具体操作。因为需要查询所有的Token ID，而这个Token ID 已经被我删了！！ 

抓狂十秒钟以后，大脑开始飞速运转，首先我镇定地告诉反馈问题的同事，这个问题可以查，但是需要一点时间。下午我给他回复。然后，我开始寻找所有的数据库表看看是否还有别的方式可以取到所有的token id。结果当然令人失望。 

初步判断下来，如果需要查询，那么可能需要将所有的日志全部解析一遍，拿到每条日志的token id 然后去判断是否是这个问题用户的 id。在盲目自信和压力驱使下，我很快完成了v1版本的程序。一个SQL线程读，一个线程写。问题再次出现，日志表体量比较大，直接查询太慢了。怎么办？没问题，不就是加个索引的事情嘛！加了索引，查询速度快了很多。现在的逻辑是一读，解析，回写日志表（新增了一列，考虑全部数据抽取再全部字段插入新表空间和IO开销都比较大。）开始运行了，在我的印象里，我笔记本性能不好，但是每秒跑个几百上千条不是问题，毕竟JWT解析很快的。然而，实时上却是几秒一条！怎么回事？愣了两秒，我反应过来了，因为加了索引，每次插入数据表都会导致索引的重新调整，从而带来大量的开销。此路不通！ 

之后我也尝试了单独将数据写临时表v2，直接将所有ID存在内存等，也碰到了空间、性能等方面的问题，大概是 v3 v4 v5版本的程序最终都被我放弃。 

既然这条路行不通，我也开始认真起来了，思考一二，目前日志表相关日志百万千万级，硬来肯定要吃亏啊，那要不换个思路。好！说干就干，思路如泉涌。 
首先，我知道，是用户的操作，那么可以过滤非登录用户的相关操作日志（设备请求也有token），只要取有用户token的日志就行。其次，我知道用户的具体操作是什么。好的，那么通过apiid可以过滤所有不相关的操作日志。再来，我还知道这个用户所有的登录时间，查下来只登陆过一次，在3月初。那么，就可以过滤所有3月之前的日志了。好，通过这样的一层层数据过滤，最终我只需要处理的相关日志数量是？大概3800多条！太好了。 

将程序换回v2版本的程序，改了一下代码，3800多条数据抽取到临时表。写了一条select in 查询语句，马上就找到了那条日志。 

最后将相关信息反馈给同事，搞定！一看时间，差不多前后花了3个多小时。真的是心疼！ 

痛定思痛，这件事告诉我们什么呢？我觉得体会最深的可能是如下几点了： 

>1.	系统设计时需要考虑未来的数据增量对性能的影响。增量大了以后，特别是update等需要进行特别小心的确认。因为后期还有很多索引会加上。   
>
>2.	数据删除清理，还是要有备份的好。更好地做法可能是无用数据迁移出热点表。   
>
>3.	体量大的数据，千万别硬来，尝试先缩小数据范围再处理，可能效果更好。   
>
>4.	数据上十万条、百万、千万级别以后，任何程序中的性能问题都会被放大，这也是检验程序性能的一个好方式。   
>
>5.	选正确的数据结构，不如尽量不用冗余的数据结构，内存肯定存不下，回写到别的数据表比较好。   
>
>6.	日志采集时候，缺少一些必要的处理和操作。没有kafka或者ELK等解决方案，导致日志还仅仅是停留在数据库表中的数据。   
>
>7.	整个研发流程不规范，如果规范流程化，那么在系统上线前势必会考虑到此类问题如何排查，如何处理定位的问题。这也是团队架构缺陷的问题所在。   


写在最后，本来想用Ulysses来写md的，结果发现格式不太对，还是用evernote的markdown来写吧。
